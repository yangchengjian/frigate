(window.webpackJsonp=window.webpackJsonp||[]).push([[19],{90:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return i})),n.d(t,"metadata",(function(){return l})),n.d(t,"toc",(function(){return c})),n.d(t,"default",(function(){return s}));var a=n(3),o=n(7),r=(n(0),n(99)),i={id:"advanced",title:"Advanced",sidebar_label:"Advanced"},l={unversionedId:"configuration/advanced",id:"configuration/advanced",isDocsHomePage:!1,title:"Advanced",description:"Advanced configuration",source:"@site/docs/configuration/advanced.md",slug:"/configuration/advanced",permalink:"/frigate/configuration/advanced",editUrl:"https://github.com/blakeblackshear/frigate/edit/master/docs/docs/configuration/advanced.md",version:"current",sidebar_label:"Advanced",sidebar:"docs",previous:{title:"Default available objects",permalink:"/frigate/configuration/objects"},next:{title:"Integration with Home Assistant",permalink:"/frigate/usage/home-assistant"}},c=[{value:"Advanced configuration",id:"advanced-configuration",children:[{value:"<code>motion</code>",id:"motion",children:[]},{value:"<code>detect</code>",id:"detect",children:[]},{value:"<code>logger</code>",id:"logger",children:[]},{value:"<code>environment_vars</code>",id:"environment_vars",children:[]},{value:"<code>database</code>",id:"database",children:[]},{value:"<code>detectors</code>",id:"detectors",children:[]},{value:"<code>model</code>",id:"model",children:[]}]}],d={toc:c};function s(e){var t=e.components,n=Object(o.a)(e,["components"]);return Object(r.b)("wrapper",Object(a.a)({},d,n,{components:t,mdxType:"MDXLayout"}),Object(r.b)("h2",{id:"advanced-configuration"},"Advanced configuration"),Object(r.b)("h3",{id:"motion"},Object(r.b)("inlineCode",{parentName:"h3"},"motion")),Object(r.b)("p",null,"Global motion detection config. These may also be defined at the camera level."),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-yaml"}),"motion:\n  # Optional: The threshold passed to cv2.threshold to determine if a pixel is different enough to be counted as motion. (default: shown below)\n  # Increasing this value will make motion detection less sensitive and decreasing it will make motion detection more sensitive.\n  # The value should be between 1 and 255.\n  threshold: 25\n  # Optional: Minimum size in pixels in the resized motion image that counts as motion\n  # Increasing this value will prevent smaller areas of motion from being detected. Decreasing will make motion detection more sensitive to smaller\n  # moving objects.\n  contour_area: 100\n  # Optional: Alpha value passed to cv2.accumulateWeighted when averaging the motion delta across multiple frames (default: shown below)\n  # Higher values mean the current frame impacts the delta a lot, and a single raindrop may register as motion.\n  # Too low and a fast moving person wont be detected as motion.\n  delta_alpha: 0.2\n  # Optional: Alpha value passed to cv2.accumulateWeighted when averaging frames to determine the background (default: shown below)\n  # Higher values mean the current frame impacts the average a lot, and a new object will be averaged into the background faster.\n  # Low values will cause things like moving shadows to be detected as motion for longer.\n  # https://www.geeksforgeeks.org/background-subtraction-in-an-image-using-concept-of-running-average/\n  frame_alpha: 0.2\n  # Optional: Height of the resized motion frame  (default: 1/6th of the original frame height)\n  # This operates as an efficient blur alternative. Higher values will result in more granular motion detection at the expense of higher CPU usage.\n  # Lower values result in less CPU, but small changes may not register as motion.\n  frame_height: 180\n")),Object(r.b)("h3",{id:"detect"},Object(r.b)("inlineCode",{parentName:"h3"},"detect")),Object(r.b)("p",null,"Global object detection settings. These may also be defined at the camera level."),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-yaml"}),"detect:\n  # Optional: Number of frames without a detection before frigate considers an object to be gone. (default: 5x the frame rate)\n  max_disappeared: 25\n")),Object(r.b)("h3",{id:"logger"},Object(r.b)("inlineCode",{parentName:"h3"},"logger")),Object(r.b)("p",null,"Change the default log level for troubleshooting purposes."),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-yaml"}),"logger:\n  # Optional: default log level (default: shown below)\n  default: info\n  # Optional: module by module log level configuration\n  logs:\n    frigate.mqtt: error\n")),Object(r.b)("p",null,"Available log levels are: ",Object(r.b)("inlineCode",{parentName:"p"},"debug"),", ",Object(r.b)("inlineCode",{parentName:"p"},"info"),", ",Object(r.b)("inlineCode",{parentName:"p"},"warning"),", ",Object(r.b)("inlineCode",{parentName:"p"},"error"),", ",Object(r.b)("inlineCode",{parentName:"p"},"critical")),Object(r.b)("p",null,"Examples of available modules are:"),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},Object(r.b)("inlineCode",{parentName:"li"},"frigate.app")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("inlineCode",{parentName:"li"},"frigate.mqtt")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("inlineCode",{parentName:"li"},"frigate.edgetpu")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("inlineCode",{parentName:"li"},"frigate.zeroconf")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("inlineCode",{parentName:"li"},"detector.<detector_name>")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("inlineCode",{parentName:"li"},"watchdog.<camera_name>")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("inlineCode",{parentName:"li"},"ffmpeg.<camera_name>.<sorted_roles>")," NOTE: All FFmpeg logs are sent as ",Object(r.b)("inlineCode",{parentName:"li"},"error")," level.")),Object(r.b)("h3",{id:"environment_vars"},Object(r.b)("inlineCode",{parentName:"h3"},"environment_vars")),Object(r.b)("p",null,"This section can be used to set environment variables for those unable to modify the environment of the container (ie. within Hass.io)"),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-yaml"}),"environment_vars:\n  EXAMPLE_VAR: value\n")),Object(r.b)("h3",{id:"database"},Object(r.b)("inlineCode",{parentName:"h3"},"database")),Object(r.b)("p",null,"Event and clip information is managed in a sqlite database at ",Object(r.b)("inlineCode",{parentName:"p"},"/media/frigate/clips/frigate.db"),". If that database is deleted, clips will be orphaned and will need to be cleaned up manually. They also won't show up in the Media Browser within Home Assistant."),Object(r.b)("p",null,"If you are storing your clips on a network share (SMB, NFS, etc), you may get a ",Object(r.b)("inlineCode",{parentName:"p"},"database is locked")," error message on startup. You can customize the location of the database in the config if necessary."),Object(r.b)("p",null,"This may need to be in a custom location if network storage is used for clips."),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-yaml"}),"database:\n  path: /media/frigate/clips/frigate.db\n")),Object(r.b)("h3",{id:"detectors"},Object(r.b)("inlineCode",{parentName:"h3"},"detectors")),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-yaml"}),"detectors:\n  # Required: name of the detector\n  coral:\n    # Required: type of the detector\n    # Valid values are 'edgetpu' (requires device property below) and 'cpu'.\n    type: edgetpu\n    # Optional: device name as defined here: https://coral.ai/docs/edgetpu/multiple-edgetpu/#using-the-tensorflow-lite-python-api\n    device: usb\n    # Optional: num_threads value passed to the tflite.Interpreter (default: shown below)\n    # This value is only used for CPU types\n    num_threads: 3\n")),Object(r.b)("h3",{id:"model"},Object(r.b)("inlineCode",{parentName:"h3"},"model")),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-yaml"}),"model:\n  # Required: height of the trained model\n  height: 320\n  # Required: width of the trained model\n  width: 320\n")))}s.isMDXComponent=!0},99:function(e,t,n){"use strict";n.d(t,"a",(function(){return b})),n.d(t,"b",(function(){return p}));var a=n(0),o=n.n(a);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function c(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var d=o.a.createContext({}),s=function(e){var t=o.a.useContext(d),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},b=function(e){var t=s(e.components);return o.a.createElement(d.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return o.a.createElement(o.a.Fragment,{},t)}},m=o.a.forwardRef((function(e,t){var n=e.components,a=e.mdxType,r=e.originalType,i=e.parentName,d=c(e,["components","mdxType","originalType","parentName"]),b=s(n),m=a,p=b["".concat(i,".").concat(m)]||b[m]||u[m]||r;return n?o.a.createElement(p,l(l({ref:t},d),{},{components:n})):o.a.createElement(p,l({ref:t},d))}));function p(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=n.length,i=new Array(r);i[0]=m;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l.mdxType="string"==typeof e?e:a,i[1]=l;for(var d=2;d<r;d++)i[d]=n[d];return o.a.createElement.apply(null,i)}return o.a.createElement.apply(null,n)}m.displayName="MDXCreateElement"}}]);